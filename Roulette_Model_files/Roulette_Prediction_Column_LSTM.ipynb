{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "# data = pd.read_excel(\"NEW DATA SHEET (copy) with features.xlsx\")  \n",
    "data=pd.read_excel(\"Roulette_data.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>dozen</th>\n",
       "      <th>column</th>\n",
       "      <th>parity</th>\n",
       "      <th>color</th>\n",
       "      <th>series</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>D1</td>\n",
       "      <td>C3</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>B</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>D1</td>\n",
       "      <td>C1</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>C</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>D3</td>\n",
       "      <td>C2</td>\n",
       "      <td>ODD</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>D2</td>\n",
       "      <td>C2</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>B</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number dozen column parity  color series group\n",
       "0       6    D1     C3   EVEN  BLACK      B    G2\n",
       "1      10    D1     C1   EVEN  BLACK      C    G2\n",
       "2      35    D3     C2    ODD  BLACK      A    G1\n",
       "3       0     0      0      0  GREEN      A    G1\n",
       "4      20    D2     C2   EVEN  BLACK      B    G2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_columns=['Dozen', 'Column', 'odd/even', 'red / black', 'series', \"Group\"]   \n",
    "categorical_columns=['dozen', 'column', 'parity', 'color', 'series', 'group']\n",
    "# Convert all categorical columns to strings to ensure uniformity\n",
    "data[categorical_columns] = data[categorical_columns].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dozen\n",
       "D1    22014\n",
       "D2    21870\n",
       "D3    21641\n",
       "0      1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dozen.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "series\n",
       "A    30894\n",
       "C    21981\n",
       "B    14527\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "G1    34591\n",
       "G2    32811\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.group.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'dozen', 'column', 'parity', 'color', 'series', 'group'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dozen\n",
      "D1    22014\n",
      "D2    21870\n",
      "D3    21641\n",
      "0      1877\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "column\n",
      "C2    22025\n",
      "C3    21781\n",
      "C1    21719\n",
      "0      1877\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "parity\n",
      "EVEN    32959\n",
      "ODD     32566\n",
      "0        1877\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "color\n",
      "BLACK    32804\n",
      "RED      32721\n",
      "GREEN     1877\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "series\n",
      "A    30894\n",
      "C    21981\n",
      "B    14527\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "group\n",
      "G1    34591\n",
      "G2    32811\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  ['Dozen', 'Column', 'odd/even', 'red / black', 'series','Group']\n",
    "for i in ['dozen', 'column', 'parity', 'color', 'series', 'group']:\n",
    "    # print(i)\n",
    "    print(data[i].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.Dozen.replace({\"D 1\":\"D1\", \"D 2\":\"D2\", \"D 3\":\"D3\"}, inplace=True)\n",
    "# data.Column.replace({\"C 1\":\"C1\", \"C 2\":\"C2\", \"C 3\":\"C3\"}, inplace=True)\n",
    "# data[\"odd/even\"].replace({\"nan\":\"0\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dozen\n",
       "D1    22014\n",
       "D2    21870\n",
       "D3    21641\n",
       "0      1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dozen.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column\n",
       "C2    22025\n",
       "C3    21781\n",
       "C1    21719\n",
       "0      1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.column.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.Column.replace({\"C 1\":\"C1\", \"C 2\":\"C2\", \"C 3\":\"C3\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parity\n",
       "EVEN    32959\n",
       "ODD     32566\n",
       "0        1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"parity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>dozen</th>\n",
       "      <th>column</th>\n",
       "      <th>parity</th>\n",
       "      <th>color</th>\n",
       "      <th>series</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67165</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67262</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67331</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67347</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67378</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1877 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       number dozen column parity  color series group\n",
       "3           0     0      0      0  GREEN      A    G1\n",
       "9           0     0      0      0  GREEN      A    G1\n",
       "43          0     0      0      0  GREEN      A    G1\n",
       "182         0     0      0      0  GREEN      A    G1\n",
       "433         0     0      0      0  GREEN      A    G1\n",
       "...       ...   ...    ...    ...    ...    ...   ...\n",
       "67165       0     0      0      0  GREEN      A    G1\n",
       "67262       0     0      0      0  GREEN      A    G1\n",
       "67331       0     0      0      0  GREEN      A    G1\n",
       "67347       0     0      0      0  GREEN      A    G1\n",
       "67378       0     0      0      0  GREEN      A    G1\n",
       "\n",
       "[1877 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"parity\"]==\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"odd/even\"].replace({\"nan\":0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "series\n",
       "A    30894\n",
       "C    21981\n",
       "B    14527\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"series\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "color\n",
       "BLACK    32804\n",
       "RED      32721\n",
       "GREEN     1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"color\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "G1    34591\n",
       "G2    32811\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dozen\n",
       "D1    22014\n",
       "D2    21870\n",
       "D3    21641\n",
       "0      1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"dozen\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column\n",
       "C2    22025\n",
       "C3    21781\n",
       "C1    21719\n",
       "0      1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"column\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'dozen', 'column', 'parity', 'color', 'series', 'group'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>dozen</th>\n",
       "      <th>column</th>\n",
       "      <th>parity</th>\n",
       "      <th>color</th>\n",
       "      <th>series</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>D1</td>\n",
       "      <td>C3</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>B</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>D1</td>\n",
       "      <td>C1</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>C</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>D3</td>\n",
       "      <td>C2</td>\n",
       "      <td>ODD</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>D2</td>\n",
       "      <td>C2</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>B</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number dozen column parity  color series group\n",
       "0       6    D1     C3   EVEN  BLACK      B    G2\n",
       "1      10    D1     C1   EVEN  BLACK      C    G2\n",
       "2      35    D3     C2    ODD  BLACK      A    G1\n",
       "3       0     0      0      0  GREEN      A    G1\n",
       "4      20    D2     C2   EVEN  BLACK      B    G2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'dozen', 'column', 'parity', 'color', 'series', 'group'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_data[model_data[\"Dozen\"]==\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows with 0 in Dozen, Column, odd/even, red/black, series, Group\n",
    "# model_data=model_data[model_data[\"Dozen\"]!=\"0\"]\n",
    "# model_data[model_data[\"Column\"]==\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in ['Dozen', 'Column', 'odd/even', 'red / black', 'series',\"Group\"]:\n",
    "#     print(i, model_data[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'dozen', 'column', 'parity', 'color', 'series', 'group'], dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>dozen</th>\n",
       "      <th>column</th>\n",
       "      <th>parity</th>\n",
       "      <th>color</th>\n",
       "      <th>series</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>D1</td>\n",
       "      <td>C3</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>B</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>D1</td>\n",
       "      <td>C1</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>C</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>D3</td>\n",
       "      <td>C2</td>\n",
       "      <td>ODD</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>D2</td>\n",
       "      <td>C2</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>B</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number dozen column parity  color series group\n",
       "0       6    D1     C3   EVEN  BLACK      B    G2\n",
       "1      10    D1     C1   EVEN  BLACK      C    G2\n",
       "2      35    D3     C2    ODD  BLACK      A    G1\n",
       "3       0     0      0      0  GREEN      A    G1\n",
       "4      20    D2     C2   EVEN  BLACK      B    G2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in ['Dozen', 'Column', 'odd/even', 'red / black', 'series',\n",
    "#        'Group']:\n",
    "#     print(i, model_data[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number     int64\n",
       "dozen     object\n",
       "column    object\n",
       "parity    object\n",
       "color     object\n",
       "series    object\n",
       "group     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Column_data=model_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns=['dozen', 'column', 'parity', 'color', 'series', 'group']\n",
    "\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    Column_data[column] = le.fit_transform(Column_data[column])\n",
    "    label_encoders[column] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>dozen</th>\n",
       "      <th>column</th>\n",
       "      <th>parity</th>\n",
       "      <th>color</th>\n",
       "      <th>series</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number  dozen  column  parity  color  series  group\n",
       "0       6      1       3       1      0       1      1\n",
       "1      10      1       1       1      0       2      1\n",
       "2      35      3       2       2      0       0      0\n",
       "3       0      0       0       0      1       0      0\n",
       "4      20      2       2       1      0       1      1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Column_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dozen dozen\n",
      "1    22014\n",
      "2    21870\n",
      "3    21641\n",
      "0     1877\n",
      "Name: count, dtype: int64\n",
      "column column\n",
      "2    22025\n",
      "3    21781\n",
      "1    21719\n",
      "0     1877\n",
      "Name: count, dtype: int64\n",
      "parity parity\n",
      "1    32959\n",
      "2    32566\n",
      "0     1877\n",
      "Name: count, dtype: int64\n",
      "color color\n",
      "0    32804\n",
      "2    32721\n",
      "1     1877\n",
      "Name: count, dtype: int64\n",
      "series series\n",
      "0    30894\n",
      "2    21981\n",
      "1    14527\n",
      "Name: count, dtype: int64\n",
      "group group\n",
      "0    34591\n",
      "1    32811\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in categorical_columns:\n",
    "    print(i, Column_data[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_Even_data=Column_data.drop([\"number\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dozen</th>\n",
       "      <th>column</th>\n",
       "      <th>parity</th>\n",
       "      <th>color</th>\n",
       "      <th>series</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dozen  column  parity  color  series  group\n",
       "0      1       3       1      0       1      1\n",
       "1      1       1       1      0       2      1\n",
       "2      3       2       2      0       0      0\n",
       "3      0       0       0      1       0      0\n",
       "4      2       2       1      0       1      1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_Even_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Check for columns with non-numeric data\n",
    "    print(\"Checking data types before preprocessing:\")\n",
    "    print(data.dtypes)\n",
    "\n",
    "    # Normalize 'Dozen', \"series\" and 'Column' values (if they are now numeric)\n",
    "    scaler = StandardScaler()\n",
    "    data[['dozen', 'group', 'parity', 'color', 'series']] = scaler.fit_transform(data[['dozen', 'group', 'parity', 'color', 'series']])\n",
    "\n",
    "    # Fill missing values if necessary\n",
    "    data = data.fillna(0)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# data = preprocess_data(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data types before preprocessing:\n",
      "dozen     int64\n",
      "column    int64\n",
      "parity    int64\n",
      "color     int64\n",
      "series    int64\n",
      "group     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data=preprocess_data(odd_Even_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dozen</th>\n",
       "      <th>column</th>\n",
       "      <th>parity</th>\n",
       "      <th>color</th>\n",
       "      <th>series</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.080172</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.826206</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>0.150993</td>\n",
       "      <td>1.026767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.080172</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.826206</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>1.292836</td>\n",
       "      <td>1.026767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.221077</td>\n",
       "      <td>2</td>\n",
       "      <td>0.988384</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>-0.990850</td>\n",
       "      <td>-0.973931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.230796</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.640796</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>-0.990850</td>\n",
       "      <td>-0.973931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.070452</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.826206</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>0.150993</td>\n",
       "      <td>1.026767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dozen  column    parity     color    series     group\n",
       "0 -1.080172       3 -0.826206 -1.012974  0.150993  1.026767\n",
       "1 -1.080172       1 -0.826206 -1.012974  1.292836  1.026767\n",
       "2  1.221077       2  0.988384 -1.012974 -0.990850 -0.973931\n",
       "3 -2.230796       0 -2.640796  0.001249 -0.990850 -0.973931\n",
       "4  0.070452       2 -0.826206 -1.012974  0.150993  1.026767"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Prepare features (X) and target (y)\n",
    "# # We will predict 'series' for the next round\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "\n",
    "# sequence_length = 5  # Number of previous rounds to consider as input\n",
    "# for i in range(len(data) - sequence_length):\n",
    "#     # print(\"-------------------\")\n",
    "#     # print(i+sequence_length)\n",
    "#     # print(data.iloc[i:i+sequence_length].drop(columns=['Group']).values)\n",
    "#     X.append(data.iloc[i:i+sequence_length].drop(columns=['Group']).values)# Features (all columns except 'series')\n",
    "    \n",
    "#     # print(data.iloc[i+sequence_length]['Group'])\n",
    "#     # print(\"________________\")\n",
    "#     y.append(data.iloc[i+sequence_length]['Group'])  # Target (next round's 'series')\n",
    "\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "\n",
    "# # Reshape X for LSTM [samples, time steps, features]\n",
    "# X = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['group'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dozen</th>\n",
       "      <th>column</th>\n",
       "      <th>parity</th>\n",
       "      <th>color</th>\n",
       "      <th>series</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.080172</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.826206</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>0.150993</td>\n",
       "      <td>1.026767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.080172</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.826206</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>1.292836</td>\n",
       "      <td>1.026767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.221077</td>\n",
       "      <td>2</td>\n",
       "      <td>0.988384</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>-0.990850</td>\n",
       "      <td>-0.973931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.230796</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.640796</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>-0.990850</td>\n",
       "      <td>-0.973931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.070452</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.826206</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>0.150993</td>\n",
       "      <td>1.026767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.080172</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.826206</td>\n",
       "      <td>1.015471</td>\n",
       "      <td>-0.990850</td>\n",
       "      <td>-0.973931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.221077</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.826206</td>\n",
       "      <td>1.015471</td>\n",
       "      <td>1.292836</td>\n",
       "      <td>1.026767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.080172</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.826206</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>-0.990850</td>\n",
       "      <td>-0.973931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.080172</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988384</td>\n",
       "      <td>1.015471</td>\n",
       "      <td>-0.990850</td>\n",
       "      <td>-0.973931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.230796</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.640796</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>-0.990850</td>\n",
       "      <td>-0.973931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dozen  column    parity     color    series     group\n",
       "0 -1.080172       3 -0.826206 -1.012974  0.150993  1.026767\n",
       "1 -1.080172       1 -0.826206 -1.012974  1.292836  1.026767\n",
       "2  1.221077       2  0.988384 -1.012974 -0.990850 -0.973931\n",
       "3 -2.230796       0 -2.640796  0.001249 -0.990850 -0.973931\n",
       "4  0.070452       2 -0.826206 -1.012974  0.150993  1.026767\n",
       "5 -1.080172       3 -0.826206  1.015471 -0.990850 -0.973931\n",
       "6  1.221077       3 -0.826206  1.015471  1.292836  1.026767\n",
       "7 -1.080172       1 -0.826206 -1.012974 -0.990850 -0.973931\n",
       "8 -1.080172       1  0.988384  1.015471 -0.990850 -0.973931\n",
       "9 -2.230796       0 -2.640796  0.001249 -0.990850 -0.973931"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(0), np.int64(1), np.int64(2), np.int64(3)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features=list(np.unique(data[\"column\"].values))\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prepare features (X) and target (y)\n",
    "X = []\n",
    "y = []\n",
    "time_steps = 10\n",
    "num_features=list(np.unique(data[\"column\"].values))\n",
    "# sequence_length = 5  # Number of previous rounds to consider as input\n",
    "for i in range(len(data) - time_steps):\n",
    "    # print(\"-------------------\")\n",
    "\n",
    "    X.append(data.iloc[i:i+time_steps].drop(columns=['column']).values)# Features (all columns except 'series')\n",
    "    y.append(data.iloc[i+time_steps]['column'])  # Target (next round's 'series')\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "# Reshape X for LSTM [samples, time steps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "num_features = X.shape[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Step 2: Prepare features (X) and target (y)\n",
    "# # We will predict 'series' for the next round\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "# time_steps = 50\n",
    "# num_features=list(np.unique(labels))\n",
    "# # sequence_length = 5  # Number of previous rounds to consider as input\n",
    "# for i in range(len(data) - time_steps):\n",
    "#     # print(\"-------------------\")\n",
    "#     # print(data.iloc[i:i+sequence_length].drop(columns=['Group']).values)\n",
    "#     X.append(data.iloc[i:i+time_steps].drop(columns=['Group']).values)# Features (all columns except 'series')\n",
    "#     y.append(data.iloc[i+time_steps]['Group'])  # Target (next round's 'series')\n",
    "\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "\n",
    "# # Reshape X for LSTM [samples, time steps, features]\n",
    "# X = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "# num_features = X.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column\n",
       "2    22025\n",
       "3    21781\n",
       "1    21719\n",
       "0     1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"column\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split (No separate validation set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X\n",
    "y_train=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67392, 10, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)  # Expected: (number_of_samples, time_steps, num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the LSTM Model\n",
    "# model = Sequential([\n",
    "#     LSTM(64, activation='tanh', return_sequences=True, input_shape=(time_steps, X_train.shape[2])),\n",
    "#     Dropout(0.1),\n",
    "#     LSTM(32, activation='tanh'),\n",
    "#     Dropout(0.1),\n",
    "#     Dense(16, activation='relu'),\n",
    "#     Dense(4, activation='softmax')  # Use 4 units for 4 classes (0, 1, 2, 3)\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # ================================\n",
    "# # Step 3: Train the Model\n",
    "# # ================================\n",
    "# # Callbacks for early stopping and saving the best model\n",
    "# early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "# model_checkpoint = ModelCheckpoint('best_model2.keras', monitor='loss', save_best_only=True)\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     epochs=50,\n",
    "#     batch_size=32,\n",
    "#     callbacks=[early_stopping, model_checkpoint]\n",
    "# )\n",
    "\n",
    "# # Evaluate the model\n",
    "# accuracy = model.evaluate(X_test, y_test)\n",
    "# print(f\"Test Accuracy: {accuracy[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # ================================\n",
    "# # Step 2: Build the LSTM Model\n",
    "# # ================================\n",
    "# num_classes = 4  # Number of classes\n",
    "# time_steps = X_train.shape[1]\n",
    "# num_features = X_train.shape[2]\n",
    "\n",
    "# model = Sequential([\n",
    "#     LSTM(32, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.01), input_shape=(time_steps, num_features)),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "#     Dense(num_classes, activation='softmax')  # Use softmax for multi-class classification\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # ================================\n",
    "# # Step 3: Train the Model\n",
    "# # ================================\n",
    "# # Callbacks for early stopping, model checkpoint, and learning rate reduction\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# model_checkpoint = ModelCheckpoint('best_model_Column.keras', monitor='val_loss', save_best_only=True)\n",
    "# lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-3)\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     epochs=50,\n",
    "#     batch_size=32,\n",
    "#     callbacks=[early_stopping, model_checkpoint, lr_scheduler]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # ================================\n",
    "# # Step 2: Build the LSTM Model\n",
    "# # ================================\n",
    "# num_classes = 4  # Number of classes\n",
    "# time_steps = X_train.shape[1]\n",
    "# num_features = X_train.shape[2]\n",
    "\n",
    "# model = Sequential([\n",
    "#     LSTM(32, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.01), input_shape=(time_steps, num_features)),\n",
    "#     Dropout(0.1),\n",
    "#     Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "#     Dense(num_classes, activation='softmax')  # Use softmax for multi-class classification\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # ================================\n",
    "# # Step 3: Train the Model\n",
    "# # ================================\n",
    "# # Callbacks for model checkpoint and learning rate reduction\n",
    "# model_checkpoint = ModelCheckpoint('best_model_Column.keras', monitor='val_loss', save_best_only=True)\n",
    "# lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-3)\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     epochs=50,\n",
    "#     batch_size=32,\n",
    "#     callbacks=[model_checkpoint, lr_scheduler]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Work\\Roulet_Pred\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3243 - loss: 1.2162\n",
      "Epoch 2/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3229 - loss: 1.1951\n",
      "Epoch 3/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3247 - loss: 1.1985\n",
      "Epoch 4/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.3210 - loss: 1.1950\n",
      "Epoch 5/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3233 - loss: 1.1952\n",
      "Epoch 6/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3269 - loss: 1.1968\n",
      "Epoch 7/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3199 - loss: 1.1956\n",
      "Epoch 8/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3288 - loss: 1.1929\n",
      "Epoch 9/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3254 - loss: 1.1936\n",
      "Epoch 10/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.3244 - loss: 1.1960\n",
      "Epoch 11/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3299 - loss: 1.1967\n",
      "Epoch 12/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3259 - loss: 1.1945\n",
      "Epoch 13/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.3265 - loss: 1.1966\n",
      "Epoch 14/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3296 - loss: 1.1965\n",
      "Epoch 15/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3302 - loss: 1.1953\n",
      "Epoch 16/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3311 - loss: 1.1925\n",
      "Epoch 17/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.3337 - loss: 1.1937\n",
      "Epoch 18/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3330 - loss: 1.1935\n",
      "Epoch 19/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.3342 - loss: 1.1907\n",
      "Epoch 20/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.3382 - loss: 1.1911\n",
      "Epoch 21/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3433 - loss: 1.1897\n",
      "Epoch 22/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3426 - loss: 1.1878\n",
      "Epoch 23/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3467 - loss: 1.1860\n",
      "Epoch 24/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.3510 - loss: 1.1852\n",
      "Epoch 25/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3511 - loss: 1.1822\n",
      "Epoch 26/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3554 - loss: 1.1784\n",
      "Epoch 27/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3588 - loss: 1.1771\n",
      "Epoch 28/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3647 - loss: 1.1735\n",
      "Epoch 29/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3628 - loss: 1.1731\n",
      "Epoch 30/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.3659 - loss: 1.1698\n",
      "Epoch 31/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3742 - loss: 1.1656\n",
      "Epoch 32/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.3739 - loss: 1.1631\n",
      "Epoch 33/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3731 - loss: 1.1602\n",
      "Epoch 34/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3784 - loss: 1.1584\n",
      "Epoch 35/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3820 - loss: 1.1520\n",
      "Epoch 36/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3873 - loss: 1.1494\n",
      "Epoch 37/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3905 - loss: 1.1483\n",
      "Epoch 38/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.3870 - loss: 1.1465\n",
      "Epoch 39/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3938 - loss: 1.1398\n",
      "Epoch 40/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3954 - loss: 1.1392\n",
      "Epoch 41/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.3969 - loss: 1.1343\n",
      "Epoch 42/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.4017 - loss: 1.1303\n",
      "Epoch 43/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4021 - loss: 1.1305\n",
      "Epoch 44/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4054 - loss: 1.1260\n",
      "Epoch 45/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.4080 - loss: 1.1201\n",
      "Epoch 46/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4093 - loss: 1.1188\n",
      "Epoch 47/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4126 - loss: 1.1216\n",
      "Epoch 48/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4142 - loss: 1.1134\n",
      "Epoch 49/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4190 - loss: 1.1104\n",
      "Epoch 50/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.4178 - loss: 1.1089\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4572 - loss: 1.0684\n",
      "Test Accuracy: 45.70%\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "num_classes = 4  # Number of classes\n",
    "time_steps = 10\n",
    "num_features = X_train.shape[2]\n",
    "\n",
    "# Build the LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', return_sequences=True, input_shape=(time_steps, num_features)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  # Use 4 units for 4 classes (0, 1, 2, 3)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ================================\n",
    "# Step 3: Train the Model\n",
    "# ================================\n",
    "# Callbacks for early stopping and saving the best model\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model_odd_even.keras', monitor='loss', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 45.70%\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 4: Evaluate the Model\n",
    "# ================================\n",
    "accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {accuracy[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ================================\n",
    "# # Step 5: Visualize Training Results\n",
    "# # ================================\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Plot training and validation loss\n",
    "# plt.plot(history.history['loss'], label='Train Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# plt.legend()\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot training and validation accuracy\n",
    "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.legend()\n",
    "# plt.title('Accuracy')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "Predicted probabilities: [[1.2246221e-02 3.5460231e-01 3.1178683e-01 3.2136473e-01]\n",
      " [3.1290021e-02 2.7931032e-01 3.4037760e-01 3.4902203e-01]\n",
      " [2.2350939e-02 3.5240078e-01 3.2060388e-01 3.0464447e-01]\n",
      " ...\n",
      " [5.5468831e-02 2.8646335e-01 3.2935733e-01 3.2871053e-01]\n",
      " [3.1523916e-04 2.3243180e-01 2.3024274e-01 5.3701019e-01]\n",
      " [4.8047397e-02 3.1746534e-01 2.9941106e-01 3.3507618e-01]]\n",
      "Predicted class: [1 3 1 1 3 1 2 3 3 2 3 3 1 1 0 1 1 3 3 3 3 2 1 1 3 3 1 3 2 2 2 3 3 3 2 1 2\n",
      " 3 2 1 1 2 3 2 2 2 3 2 2 3 2 1 3 1 3 2 3 0 1 1 2 1 2 2 3 3 2 1 1 3 3 2 2 1\n",
      " 3 3 3 3 3 2 2 2 2 2 3 2 1 3 3 2 1 3 2 2 1 3 2 3 2 3 3 1 2 1 3 2 3 2 1 3 2\n",
      " 2 1 2 1 1 2 3 1 1 3 3 2 1 2 3 3 2 3 3 1 3 1 3 2 3 3 3 1 3 2 3 3 3 2 2 1 1\n",
      " 2 1 0 3 1 2 3 3 1 2 3 2 3 3 1 3 3 2 2 1 1 2 2 3 3 0 2 2 2 3 3 1 2 1 3 3 1\n",
      " 1 1 3 3 2 3 2 3 2 3 1 3 1 2 2 3 2 3 2 2 3 2 2 3 3 3 3 2 3 3 2 2 3 1 3 2 3\n",
      " 3 2 2 1 3 1 2 3 3 1 2 3 2 2 2 2 3 2 1 2 2 3 3 3 2 1 2 2 2 1 3 2 3 2 3 1 3\n",
      " 2 3 3 3 2 3 1 2 2 0 3 1 1 2 2 1 1 1 2 1 3 2 1 3 3 3 3 1 3 2 1 2 1 2 3 1 2\n",
      " 1 3 1 1 2 3 1 3 3 1 1 3 2 2 2 2 3 3 2 1 2 2 3 2 1 2 2 2 3 3 1 1 3 1 2 3 1\n",
      " 1 1 2 2 2 3 1 3 1 3 3 2 1 1 2 2 2 3 2 1 1 1 2 3 3 2 1 1 1 2 1 3 1 3 3 3 1\n",
      " 1 2 3 1 2 2 1 1 1 1 3 2 3 1 1 2 2 1 2 3 2 3 2 1 2 1 2 1 2 3 3 1 3 2 1 1 2\n",
      " 2 3 2 1 2 2 2 2 3 2 3 3 2 3 2 3 1 3 3 3 3 3 3 1 3 3 3 3 1 1 2 1 3 2 1 3 1\n",
      " 1 1 1 2 2 3 2 2 1 3 3 1 2 1 2 2 1 3 1 3 3 2 2 1 1 2 2 3 1 1 3 3 2 1 1 3 2\n",
      " 3 2 3 0 2 1 3 2 2 1 2 3 3 2 3 3 3 1 3 3 1 1 3 3 3 3 1 3 3 1 2 2 2 1 3 3 2\n",
      " 1 3 3 2 1 1 1 3 3 3 3 1 1 2 3 1 1 3 3 2 1 1 2 1 3 2 3 1 1 2 3 2 3 3 3 2 2\n",
      " 3 1 3 2 1 1 1 1 3 1 2 2 1 3 1 1 3 1 1 2 1 3 3 1 2 3 1 1 3 2 0 2 1 3 2 1 1\n",
      " 1 1 2 1 3 2 2 1 2 2 2 2 2 1 3 3 2 3 1 1 3 1 2 1 3 3 3 3 1 3 1 1 0 2 1 3 2\n",
      " 3 3 2 1 1 2 2 1 1 3 2 1 3 3 3 2 2 3 3 2 3 1 1 3 3 1 1 1 2 2 1 2 2 2 1 1 3\n",
      " 2 2 2 3 3 2 3 3]\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 4: Evaluate the Model\n",
    "# ================================\n",
    "# Evaluate on the test set\n",
    "# Predict on new data (example usage)\n",
    "new_data = X_test  # Take one example from the test set\n",
    "\n",
    "# Perform the prediction\n",
    "prediction_probs = model.predict(new_data)  # This outputs probabilities for all classes\n",
    "predicted_class = np.argmax(prediction_probs, axis=-1)  # Extract the class index with the highest probability\n",
    "\n",
    "print(\"Predicted probabilities:\", prediction_probs)\n",
    "print(\"Predicted class:\",predicted_class)  # Single class output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 45.70%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted_class)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(X_test)\n",
    "# y_pred = (y_pred_prob > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 5)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "X_test[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.08017199e+00,  9.88383749e-01,  1.01547137e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [-1.08017199e+00,  9.88383749e-01,  1.01547137e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [ 7.04523082e-02, -8.26206218e-01, -1.01297351e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [ 1.22107661e+00,  9.88383749e-01, -1.01297351e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [ 7.04523082e-02, -8.26206218e-01,  1.01547137e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [ 7.04523082e-02,  9.88383749e-01,  1.01547137e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [ 1.22107661e+00, -8.26206218e-01, -1.01297351e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [-1.08017199e+00,  9.88383749e-01,  1.01547137e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [ 7.04523082e-02,  9.88383749e-01,  1.01547137e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [ 1.22107661e+00,  9.88383749e-01,  1.01547137e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [-1.08017199e+00, -8.26206218e-01, -1.01297351e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [ 7.04523082e-02, -8.26206218e-01,  1.01547137e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [ 1.22107661e+00,  9.88383749e-01,  1.01547137e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [ 7.04523082e-02, -8.26206218e-01, -1.01297351e+00,\n",
       "          1.50993225e-01,  1.02676682e+00],\n",
       "        [ 1.22107661e+00, -8.26206218e-01,  1.01547137e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [ 1.22107661e+00,  9.88383749e-01,  1.01547137e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [ 1.22107661e+00,  9.88383749e-01,  1.01547137e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [ 7.04523082e-02, -8.26206218e-01,  1.01547137e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [ 7.04523082e-02,  9.88383749e-01, -1.01297351e+00,\n",
       "          1.50993225e-01, -9.73930967e-01],\n",
       "        [ 7.04523082e-02, -8.26206218e-01, -1.01297351e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [-1.08017199e+00, -8.26206218e-01, -1.01297351e+00,\n",
       "          1.50993225e-01,  1.02676682e+00],\n",
       "        [-1.08017199e+00, -8.26206218e-01, -1.01297351e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [ 1.22107661e+00, -8.26206218e-01,  1.01547137e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [ 1.22107661e+00, -8.26206218e-01,  1.01547137e+00,\n",
       "          1.50993225e-01,  1.02676682e+00],\n",
       "        [-1.08017199e+00, -8.26206218e-01, -1.01297351e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [-1.08017199e+00, -8.26206218e-01,  1.01547137e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [ 1.22107661e+00,  9.88383749e-01, -1.01297351e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [-1.08017199e+00,  9.88383749e-01,  1.01547137e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [-1.08017199e+00, -8.26206218e-01, -1.01297351e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [ 7.04523082e-02, -8.26206218e-01,  1.01547137e+00,\n",
       "          1.50993225e-01,  1.02676682e+00],\n",
       "        [ 7.04523082e-02,  9.88383749e-01,  1.01547137e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [ 7.04523082e-02,  9.88383749e-01, -1.01297351e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [ 7.04523082e-02, -8.26206218e-01,  1.01547137e+00,\n",
       "          1.50993225e-01,  1.02676682e+00],\n",
       "        [-2.23079629e+00, -2.64079618e+00,  1.24893123e-03,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [-1.08017199e+00, -8.26206218e-01,  1.01547137e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [ 7.04523082e-02,  9.88383749e-01,  1.01547137e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [-1.08017199e+00,  9.88383749e-01,  1.01547137e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [ 1.22107661e+00, -8.26206218e-01,  1.01547137e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [ 1.22107661e+00,  9.88383749e-01,  1.01547137e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [-1.08017199e+00, -8.26206218e-01, -1.01297351e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [-2.23079629e+00, -2.64079618e+00,  1.24893123e-03,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [ 1.22107661e+00, -8.26206218e-01,  1.01547137e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [ 7.04523082e-02, -8.26206218e-01, -1.01297351e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [ 1.22107661e+00, -8.26206218e-01,  1.01547137e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [ 7.04523082e-02,  9.88383749e-01,  1.01547137e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [-1.08017199e+00,  9.88383749e-01,  1.01547137e+00,\n",
       "          1.50993225e-01,  1.02676682e+00],\n",
       "        [-1.08017199e+00, -8.26206218e-01, -1.01297351e+00,\n",
       "          1.50993225e-01,  1.02676682e+00],\n",
       "        [ 1.22107661e+00, -8.26206218e-01,  1.01547137e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01],\n",
       "        [ 1.22107661e+00,  9.88383749e-01,  1.01547137e+00,\n",
       "          1.29283608e+00,  1.02676682e+00],\n",
       "        [ 1.22107661e+00, -8.26206218e-01, -1.01297351e+00,\n",
       "         -9.90849631e-01, -9.73930967e-01]]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# #Predict on the test set\n",
    "# y_pred_prob = model.predict(X_test[:1])\n",
    "# y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "# print(y_pred)\n",
    "# y_pred=label_encoders[\"Column\"].inverse_transform(y_pred)\n",
    "\n",
    "# # Save the model\n",
    "model.save(\"Column_lstm_model_10.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=pd.read_excel(\"NEW DATA SHEET (copy) with features.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model_path = \"best_model2.keras\"\n",
    "model = load_model(model_path)\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.02046066, 0.33429366, 0.2843635 , 0.36088213]], dtype=float32)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Dozen</th>\n",
       "      <th>Column</th>\n",
       "      <th>odd/even</th>\n",
       "      <th>red / black</th>\n",
       "      <th>series</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>D 1</td>\n",
       "      <td>C 3</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>B</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number Dozen Column odd/even red / black series Group\n",
       "0       6   D 1    C 3     EVEN       BLACK      B    G2"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "Predicted Probabilities: [0.02887887 0.31838897 0.32792342 0.3248088 ]\n",
      "Predicted Labels: 2\n",
      "Decoded Labels: C2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# ================================\n",
    "# Step 1: Load the Trained Model\n",
    "# ================================\n",
    "def load_trained_model(model_path):\n",
    "    \"\"\"Load the trained model from a file.\"\"\"\n",
    "    model = load_model(model_path)\n",
    "    print(\"Model loaded successfully.\")\n",
    "    return model\n",
    "\n",
    "# ================================\n",
    "# Step 2: Preprocess Input Data\n",
    "# ================================\n",
    "def preprocess_input(input_data):\n",
    "    \"\"\"Preprocess input data to match the model's expected shape.\"\"\"\n",
    "    # Ensure input_data is a NumPy array\n",
    "\n",
    "    categorical_columns=['Dozen', 'Column', 'odd/even', 'red / black', 'series', \"Group\"]\n",
    "\n",
    "    # Convert all categorical columns to strings to ensure uniformity\n",
    "    input_data[categorical_columns] = input_data[categorical_columns].astype(str)\n",
    "    #Preprocess categorical columns\n",
    "    input_data = input_data.drop([\"Number\"], axis=1)\n",
    "    input_data[\"Dozen\"].replace({\"D 1\":\"D1\", \"D 2\":\"D2\", \"D 3\":\"D3\"}, inplace=True)\n",
    "    input_data[\"Column\"].replace({\"C 1\":\"C1\", \"C 2\":\"C2\", \"C 3\":\"C3\"}, inplace=True)\n",
    "    input_data[\"odd/even\"].replace({\"nan\":\"0\"}, inplace=True)\n",
    "\n",
    "    label_encoders = {}\n",
    "    for column in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        input_data[column] = le.fit_transform(input_data[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "    #Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    input_data[['series', 'Dozen', 'Group', 'red / black', 'odd/even']] = scaler.fit_transform(input_data[['series', 'Dozen', 'Group', 'red / black', 'odd/even']])\n",
    "    # Fill missing values if necessary\n",
    "    input_data = input_data.fillna(0)\n",
    "    ## Converting Data Time Series\n",
    "    # X = []\n",
    "    # y=[]\n",
    "    time_steps = 50\n",
    "    # data=data.drop([\"Number\"], axis=1)\n",
    "    X=input_data.drop(columns=['Column']).values\n",
    "    X= np.array(X)\n",
    "    # y = np.array(y)\n",
    "    # print(X.shape)\n",
    "    X = X.reshape(1, X.shape[0], X.shape[1])\n",
    "    # input_data = np.array(input_data)\n",
    "\n",
    "    return X \n",
    "\n",
    "# ================================\n",
    "# Step 3: Perform Inference\n",
    "# ================================\n",
    "def predict_class(model, X):\n",
    "    \"\"\"Predict class probabilities and labels for the input data.\"\"\"\n",
    "    # Get probabilities\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    # Convert probabilities to binary labels (0 or 1)\n",
    "    # predicted_labels = (probabilities > 0.5).astype(int)\n",
    "    # print(predicted_labels)\n",
    "    predicted_labels = np.argmax(predictions).astype(list)\n",
    "    decoded_labels = label_encoders[\"Column\"].inverse_transform([predicted_labels])\n",
    "    \n",
    "    return predictions, predicted_labels ,decoded_labels\n",
    "# ================================\n",
    "# Step 4: Main Inference Script\n",
    "# ================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the trained model\n",
    "    model_path = \"lstm_model_Column.h5\"\n",
    "\n",
    "    # Load the model\n",
    "    model = load_trained_model(model_path)\n",
    "\n",
    "    # Example input data (replace with actual test input)\n",
    "    # Example assumes time_steps=10, num_features=5\n",
    "    \n",
    "    sample_input =data2[50:101]  # Replace with your actual data\n",
    "\n",
    "    # Preprocess input data\n",
    "    preprocessed_input = preprocess_input(sample_input)\n",
    "\n",
    "    # Perform inference\n",
    "    probabilities, predicted_labels,decoded_labels = predict_class(model, preprocessed_input)\n",
    "\n",
    "    # Output the results\n",
    "    print(\"Predicted Probabilities:\", probabilities[-1])\n",
    "    print(\"Predicted Labels:\", predicted_labels)\n",
    "    print(\"Decoded Labels:\", decoded_labels[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Dozen</th>\n",
       "      <th>Column</th>\n",
       "      <th>odd/even</th>\n",
       "      <th>red / black</th>\n",
       "      <th>series</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>D 1</td>\n",
       "      <td>C 3</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>B</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number Dozen Column odd/even red / black series Group\n",
       "0       6   D 1    C 3     EVEN       BLACK      B    G2"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6777578]], dtype=float32)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(preprocessed_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # ================================\n",
    "# # Step 1: Load the Trained Model\n",
    "# # ================================\n",
    "# def load_trained_model(model_path):\n",
    "#     \"\"\"Load the trained model from a file.\"\"\"\n",
    "#     model = load_model(model_path)\n",
    "#     print(\"Model loaded successfully.\")\n",
    "#     return model\n",
    "\n",
    "# # ================================\n",
    "# # Step 2: Preprocess Input Data\n",
    "# # ================================\n",
    "# def preprocess_input(input_data, label_encoders, time_steps, num_features):\n",
    "#     \"\"\"Preprocess input data to match the model's expected shape.\"\"\"\n",
    "#     # Ensure input_data is a DataFrame\n",
    "#     categorical_columns = ['Dozen', 'Column', 'odd/even', 'red / black', 'series', 'Group']\n",
    "\n",
    "#     # Convert all categorical columns to strings to ensure uniformity\n",
    "#     input_data[categorical_columns] = input_data[categorical_columns].astype(str)\n",
    "\n",
    "#     # Convert all categorical columns to strings to ensure uniformity\n",
    "#     input_data[categorical_columns] = input_data[categorical_columns].astype(str)\n",
    "#     #Preprocess categorical columns\n",
    "#     input_data = input_data.drop([\"Number\"], axis=1)\n",
    "#     input_data[\"Dozen\"].replace({\"D 1\":\"D1\", \"D 2\":\"D2\", \"D 3\":\"D3\"}, inplace=True)\n",
    "#     input_data[\"Column\"].replace({\"C 1\":\"C1\", \"C 2\":\"C2\", \"C 3\":\"C3\"}, inplace=True)\n",
    "#     input_data[\"odd/even\"].replace({\"nan\":\"0\"}, inplace=True)\n",
    "    \n",
    "#     # Encoding categorical columns\n",
    "#     for column in categorical_columns:\n",
    "#         input_data[column] = label_encoders[column].transform(input_data[column])\n",
    "    \n",
    "#     # Normalize 'Dozen', \"series\" and 'Column' values\n",
    "#     scaler = StandardScaler()\n",
    "#     input_data[['Dozen', 'Column', 'odd/even', 'red / black', 'series']] = scaler.fit_transform(input_data[['Dozen', 'Column', 'odd/even', 'red / black', 'series']])\n",
    "\n",
    "#     # Fill missing values if necessary\n",
    "#     input_data = input_data.fillna(0)\n",
    "\n",
    "#     # Converting Data Time Series\n",
    "#     X = input_data.drop(columns=['Group'])\n",
    "#     y = input_data['Group']\n",
    "\n",
    "#     if len(X) < time_steps:\n",
    "#         padding = pd.DataFrame(np.zeros((time_steps - len(X), num_features)))\n",
    "#         X = pd.concat([padding, X], ignore_index=True)\n",
    "#     X = np.array(X.values)\n",
    "#     y = np.array(y.values)\n",
    "#     X.reshape(1, time_steps, num_features)\n",
    "\n",
    "#     return X, y\n",
    "\n",
    "# # ================================\n",
    "# # Step 3: Perform Inference\n",
    "# # ================================\n",
    "# def predict_class(model, X):\n",
    "#     \"\"\"Predict class probabilities and labels for the input data.\"\"\"\n",
    "#     # Get probabilities\n",
    "#     probabilities = model.predict(X)\n",
    "\n",
    "#     # Convert probabilities to binary labels (0 or 1)\n",
    "#     predicted_labels = (probabilities > 0.5).astype(int)\n",
    "#     return probabilities, predicted_labels\n",
    "\n",
    "# # ================================\n",
    "# # Step 4: Main Inference Script\n",
    "# # ================================\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Path to the trained model\n",
    "#     model_path = \"lstm_model.h5\"\n",
    "\n",
    "#     # Load the model\n",
    "#     model = load_trained_model(model_path)\n",
    "\n",
    "#     # Example input data (replace with actual test input)\n",
    "#     sample_input = pd.read_excel(\"NEW DATA SHEET (copy) with features.xlsx\")[:1]  # Replace with your actual data\n",
    "#     time_steps = 50\n",
    "#     num_features = 5\n",
    "#     # Preprocess input data\n",
    "#     X, y = preprocess_input(sample_input, label_encoders, time_steps, num_features)\n",
    "\n",
    "#     # Perform inference\n",
    "#     probabilities, predicted_labels = predict_class(model, X)\n",
    "\n",
    "#     # Output the results\n",
    "#     print(\"Predicted Probabilities:\", probabilities)\n",
    "#     print(\"Predicted Labels:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1=[['D2', 'C3', 'A', 'BLACK', 'EVEN', 'G1'], ['D3', 'C1', 'A', 'BLACK', 'EVEN', 'G2'], ['D3', 'C1', 'A', 'BLACK', 'ODD', 'G2'], ['D3', 'C1', 'A', 'BLACK', 'EVEN', 'G2'], ['D3', 'C3', 'A', 'BLACK', 'EVEN', 'G2'], ['D1', 'C1', 'A', 'RED', 'ODD', 'G2'], ['D1', 'C1', 'A', 'RED', 'EVEN', 'G2'], ['D1', 'C1', 'A', 'RED', 'ODD', 'G2'], ['D2', 'C1', 'A', 'BLACK', 'EVEN', 'G2'], ['D3', 'C1', 'A', 'BLACK', 'EVEN', 'G1'], ['D2', 'C1', 'A', 'RED', 'EVEN', 'G1'], ['D2', 'C1', 'C', 'RED', 'EVEN', 'G2'], ['D2', 'C1', 'A', 'RED', 'EVEN', 'G1'], ['D1', 'C3', 'B', 'RED', 'EVEN', 'G2'], ['D3', 'C3', 'A', 'RED', 'ODD', 'G2'], ['D3', 'C1', 'C', 'RED', 'EVEN', 'G2'], ['D1', 'C3', 'B', 'RED', 'ODD', 'G1'], ['D2', 'C1', 'A', 'RED', 'EVEN', 'G1'], ['D2', 'C1', 'C', 'RED', 'ODD', 'G1'], ['D3', 'C3', 'C', 'BLACK', 'ODD', 'G2'], ['D2', 'C2', 'A', 'RED', 'EVEN', 'G2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
