{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "# data = pd.read_excel(\"NEW DATA SHEET (copy) with features.xlsx\")  \n",
    "\n",
    "data=pd.read_excel(\"Roulette_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>dozen</th>\n",
       "      <th>column</th>\n",
       "      <th>parity</th>\n",
       "      <th>color</th>\n",
       "      <th>series</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>D1</td>\n",
       "      <td>C3</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>B</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>D1</td>\n",
       "      <td>C1</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>C</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>D3</td>\n",
       "      <td>C2</td>\n",
       "      <td>ODD</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>D2</td>\n",
       "      <td>C2</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>B</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number dozen column parity  color series group\n",
       "0       6    D1     C3   EVEN  BLACK      B    G2\n",
       "1      10    D1     C1   EVEN  BLACK      C    G2\n",
       "2      35    D3     C2    ODD  BLACK      A    G1\n",
       "3       0     0      0      0  GREEN      A    G1\n",
       "4      20    D2     C2   EVEN  BLACK      B    G2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_columns=['Dozen', 'Column', 'odd/even', 'red / black', 'series', \"Group\"]   \n",
    "categorical_columns=['dozen', 'column', 'parity', 'color', 'series', 'group']\n",
    "# Convert all categorical columns to strings to ensure uniformity\n",
    "data[categorical_columns] = data[categorical_columns].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dozen\n",
       "D1    22014\n",
       "D2    21870\n",
       "D3    21641\n",
       "0      1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dozen.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "series\n",
       "A    30894\n",
       "C    21981\n",
       "B    14527\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "G1    34591\n",
       "G2    32811\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.group.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'dozen', 'column', 'parity', 'color', 'series', 'group'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dozen\n",
      "D1    22014\n",
      "D2    21870\n",
      "D3    21641\n",
      "0      1877\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "column\n",
      "C2    22025\n",
      "C3    21781\n",
      "C1    21719\n",
      "0      1877\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "parity\n",
      "EVEN    32959\n",
      "ODD     32566\n",
      "0        1877\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "color\n",
      "BLACK    32804\n",
      "RED      32721\n",
      "GREEN     1877\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "series\n",
      "A    30894\n",
      "C    21981\n",
      "B    14527\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "group\n",
      "G1    34591\n",
      "G2    32811\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in ['dozen', 'column', 'parity', 'color', 'series', 'group']:\n",
    "    # print(i)\n",
    "    print(data[i].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.Dozen.replace({\"D 1\":\"D1\", \"D 2\":\"D2\", \"D 3\":\"D3\"}, inplace=True)\n",
    "# data.Column.replace({\"C 1\":\"C1\", \"C 2\":\"C2\", \"C 3\":\"C3\"}, inplace=True)\n",
    "# data[\"odd/even\"].replace({\"nan\":\"0\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dozen\n",
       "D1    22014\n",
       "D2    21870\n",
       "D3    21641\n",
       "0      1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dozen.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column\n",
       "C2    22025\n",
       "C3    21781\n",
       "C1    21719\n",
       "0      1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.column.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.Column.replace({\"C 1\":\"C1\", \"C 2\":\"C2\", \"C 3\":\"C3\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parity\n",
       "EVEN    32959\n",
       "ODD     32566\n",
       "0        1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"parity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>dozen</th>\n",
       "      <th>column</th>\n",
       "      <th>parity</th>\n",
       "      <th>color</th>\n",
       "      <th>series</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67165</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67262</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67331</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67347</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67378</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1877 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       number dozen column parity  color series group\n",
       "3           0     0      0      0  GREEN      A    G1\n",
       "9           0     0      0      0  GREEN      A    G1\n",
       "43          0     0      0      0  GREEN      A    G1\n",
       "182         0     0      0      0  GREEN      A    G1\n",
       "433         0     0      0      0  GREEN      A    G1\n",
       "...       ...   ...    ...    ...    ...    ...   ...\n",
       "67165       0     0      0      0  GREEN      A    G1\n",
       "67262       0     0      0      0  GREEN      A    G1\n",
       "67331       0     0      0      0  GREEN      A    G1\n",
       "67347       0     0      0      0  GREEN      A    G1\n",
       "67378       0     0      0      0  GREEN      A    G1\n",
       "\n",
       "[1877 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"parity\"]==\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"odd/even\"].replace({\"nan\":0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "series\n",
       "A    30894\n",
       "C    21981\n",
       "B    14527\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"series\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "color\n",
       "BLACK    32804\n",
       "RED      32721\n",
       "GREEN     1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"color\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "G1    34591\n",
       "G2    32811\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dozen\n",
       "D1    22014\n",
       "D2    21870\n",
       "D3    21641\n",
       "0      1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"dozen\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column\n",
       "C2    22025\n",
       "C3    21781\n",
       "C1    21719\n",
       "0      1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"column\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parity\n",
       "EVEN    32959\n",
       "ODD     32566\n",
       "0        1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"parity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'dozen', 'column', 'parity', 'color', 'series', 'group'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in ['Dozen', 'Column', 'odd/even', 'red / black', 'series',\n",
    "#        'Group']:\n",
    "#     print(i, data[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>dozen</th>\n",
       "      <th>column</th>\n",
       "      <th>parity</th>\n",
       "      <th>color</th>\n",
       "      <th>series</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>D1</td>\n",
       "      <td>C3</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>B</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>D1</td>\n",
       "      <td>C1</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>C</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>D3</td>\n",
       "      <td>C2</td>\n",
       "      <td>ODD</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>D2</td>\n",
       "      <td>C2</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>B</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number dozen column parity  color series group\n",
       "0       6    D1     C3   EVEN  BLACK      B    G2\n",
       "1      10    D1     C1   EVEN  BLACK      C    G2\n",
       "2      35    D3     C2    ODD  BLACK      A    G1\n",
       "3       0     0      0      0  GREEN      A    G1\n",
       "4      20    D2     C2   EVEN  BLACK      B    G2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'dozen', 'column', 'parity', 'color', 'series', 'group'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_data[model_data[\"Dozen\"]==\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows with 0 in Dozen, Column, odd/even, red/black, series, Group\n",
    "# model_data=model_data[model_data[\"Dozen\"]!=\"0\"]\n",
    "# model_data[model_data[\"Column\"]==\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dozen dozen\n",
      "D1    22014\n",
      "D2    21870\n",
      "D3    21641\n",
      "0      1877\n",
      "Name: count, dtype: int64\n",
      "column column\n",
      "C2    22025\n",
      "C3    21781\n",
      "C1    21719\n",
      "0      1877\n",
      "Name: count, dtype: int64\n",
      "parity parity\n",
      "EVEN    32959\n",
      "ODD     32566\n",
      "0        1877\n",
      "Name: count, dtype: int64\n",
      "color color\n",
      "BLACK    32804\n",
      "RED      32721\n",
      "GREEN     1877\n",
      "Name: count, dtype: int64\n",
      "series series\n",
      "A    30894\n",
      "C    21981\n",
      "B    14527\n",
      "Name: count, dtype: int64\n",
      "group group\n",
      "G1    34591\n",
      "G2    32811\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in ['dozen', 'column', 'parity', 'color', 'series', 'group']:\n",
    "    print(i, model_data[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'dozen', 'column', 'parity', 'color', 'series', 'group'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>dozen</th>\n",
       "      <th>column</th>\n",
       "      <th>parity</th>\n",
       "      <th>color</th>\n",
       "      <th>series</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>D1</td>\n",
       "      <td>C3</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>B</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>D1</td>\n",
       "      <td>C1</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>C</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>D3</td>\n",
       "      <td>C2</td>\n",
       "      <td>ODD</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>D2</td>\n",
       "      <td>C2</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>B</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number dozen column parity  color series group\n",
       "0       6    D1     C3   EVEN  BLACK      B    G2\n",
       "1      10    D1     C1   EVEN  BLACK      C    G2\n",
       "2      35    D3     C2    ODD  BLACK      A    G1\n",
       "3       0     0      0      0  GREEN      A    G1\n",
       "4      20    D2     C2   EVEN  BLACK      B    G2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in ['Dozen', 'Column', 'odd/even', 'red / black', 'series',\n",
    "#        'Group']:\n",
    "#     print(i, model_data[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number     int64\n",
       "dozen     object\n",
       "column    object\n",
       "parity    object\n",
       "color     object\n",
       "series    object\n",
       "group     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on Dozen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dozen_data=model_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns=['dozen', 'column', 'parity', 'color', 'series', 'group']\n",
    "\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    dozen_data[column] = le.fit_transform(dozen_data[column])\n",
    "    label_encoders[column] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>dozen</th>\n",
       "      <th>column</th>\n",
       "      <th>parity</th>\n",
       "      <th>color</th>\n",
       "      <th>series</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number  dozen  column  parity  color  series  group\n",
       "0       6      1       3       1      0       1      1\n",
       "1      10      1       1       1      0       2      1\n",
       "2      35      3       2       2      0       0      0\n",
       "3       0      0       0       0      1       0      0\n",
       "4      20      2       2       1      0       1      1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dozen_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dozen dozen\n",
      "1    22014\n",
      "2    21870\n",
      "3    21641\n",
      "0     1877\n",
      "Name: count, dtype: int64\n",
      "column column\n",
      "2    22025\n",
      "3    21781\n",
      "1    21719\n",
      "0     1877\n",
      "Name: count, dtype: int64\n",
      "parity parity\n",
      "1    32959\n",
      "2    32566\n",
      "0     1877\n",
      "Name: count, dtype: int64\n",
      "color color\n",
      "0    32804\n",
      "2    32721\n",
      "1     1877\n",
      "Name: count, dtype: int64\n",
      "series series\n",
      "0    30894\n",
      "2    21981\n",
      "1    14527\n",
      "Name: count, dtype: int64\n",
      "group group\n",
      "0    34591\n",
      "1    32811\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in categorical_columns:\n",
    "    print(i, dozen_data[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dozen_data=dozen_data.drop([\"number\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dozen</th>\n",
       "      <th>column</th>\n",
       "      <th>parity</th>\n",
       "      <th>color</th>\n",
       "      <th>series</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dozen  column  parity  color  series  group\n",
       "0      1       3       1      0       1      1\n",
       "1      1       1       1      0       2      1\n",
       "2      3       2       2      0       0      0\n",
       "3      0       0       0      1       0      0\n",
       "4      2       2       1      0       1      1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dozen_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Check for columns with non-numeric data\n",
    "    print(\"Checking data types before preprocessing:\")\n",
    "    print(data.dtypes)\n",
    "\n",
    "    # Normalize 'Dozen', \"series\" and 'Column' values (if they are now numeric)\n",
    "    scaler = StandardScaler()\n",
    "    data[['series', 'column', 'parity', 'color','group']] = scaler.fit_transform(data[['series', 'column', 'parity', 'color', 'group']])\n",
    "\n",
    "    # Fill missing values if necessary\n",
    "    data = data.fillna(0)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# data = preprocess_data(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data types before preprocessing:\n",
      "dozen     int64\n",
      "column    int64\n",
      "parity    int64\n",
      "color     int64\n",
      "series    int64\n",
      "group     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data=preprocess_data(dozen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dozen</th>\n",
       "      <th>column</th>\n",
       "      <th>parity</th>\n",
       "      <th>color</th>\n",
       "      <th>series</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.214899</td>\n",
       "      <td>-0.826206</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>0.150993</td>\n",
       "      <td>1.026767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.088716</td>\n",
       "      <td>-0.826206</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>1.292836</td>\n",
       "      <td>1.026767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.063091</td>\n",
       "      <td>0.988384</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>-0.990850</td>\n",
       "      <td>-0.973931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.240524</td>\n",
       "      <td>-2.640796</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>-0.990850</td>\n",
       "      <td>-0.973931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.063091</td>\n",
       "      <td>-0.826206</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>0.150993</td>\n",
       "      <td>1.026767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dozen    column    parity     color    series     group\n",
       "0      1  1.214899 -0.826206 -1.012974  0.150993  1.026767\n",
       "1      1 -1.088716 -0.826206 -1.012974  1.292836  1.026767\n",
       "2      3  0.063091  0.988384 -1.012974 -0.990850 -0.973931\n",
       "3      0 -2.240524 -2.640796  0.001249 -0.990850 -0.973931\n",
       "4      2  0.063091 -0.826206 -1.012974  0.150993  1.026767"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Prepare features (X) and target (y)\n",
    "# # We will predict 'series' for the next round\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "\n",
    "# sequence_length = 5  # Number of previous rounds to consider as input\n",
    "# for i in range(len(data) - sequence_length):\n",
    "#     # print(\"-------------------\")\n",
    "#     # print(i+sequence_length)\n",
    "#     # print(data.iloc[i:i+sequence_length].drop(columns=['Group']).values)\n",
    "#     X.append(data.iloc[i:i+sequence_length].drop(columns=['Group']).values)# Features (all columns except 'series')\n",
    "    \n",
    "#     # print(data.iloc[i+sequence_length]['Group'])\n",
    "#     # print(\"________________\")\n",
    "#     y.append(data.iloc[i+sequence_length]['Group'])  # Target (next round's 'series')\n",
    "\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "\n",
    "# # Reshape X for LSTM [samples, time steps, features]\n",
    "# X = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['dozen'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dozen</th>\n",
       "      <th>column</th>\n",
       "      <th>parity</th>\n",
       "      <th>color</th>\n",
       "      <th>series</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.214899</td>\n",
       "      <td>-0.826206</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>0.150993</td>\n",
       "      <td>1.026767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.088716</td>\n",
       "      <td>-0.826206</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>1.292836</td>\n",
       "      <td>1.026767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.063091</td>\n",
       "      <td>0.988384</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>-0.990850</td>\n",
       "      <td>-0.973931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.240524</td>\n",
       "      <td>-2.640796</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>-0.990850</td>\n",
       "      <td>-0.973931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.063091</td>\n",
       "      <td>-0.826206</td>\n",
       "      <td>-1.012974</td>\n",
       "      <td>0.150993</td>\n",
       "      <td>1.026767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dozen    column    parity     color    series     group\n",
       "0      1  1.214899 -0.826206 -1.012974  0.150993  1.026767\n",
       "1      1 -1.088716 -0.826206 -1.012974  1.292836  1.026767\n",
       "2      3  0.063091  0.988384 -1.012974 -0.990850 -0.973931\n",
       "3      0 -2.240524 -2.640796  0.001249 -0.990850 -0.973931\n",
       "4      2  0.063091 -0.826206 -1.012974  0.150993  1.026767"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prepare features (X) and target (y)\n",
    "X = []\n",
    "y = []\n",
    "time_steps = 10\n",
    "num_features=list(np.unique(labels))\n",
    "# sequence_length = 5  # Number of previous rounds to consider as input\n",
    "for i in range(len(data) - time_steps):\n",
    "    # print(\"-------------------\")\n",
    "\n",
    "    X.append(data.iloc[i:i+time_steps].drop(columns=['dozen']).values)# Features (all columns except 'series')\n",
    "    y.append(data.iloc[i+time_steps]['dozen'])  # Target (next round's 'series')\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "# Reshape X for LSTM [samples, time steps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "num_features = X.shape[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Step 2: Prepare features (X) and target (y)\n",
    "# # We will predict 'series' for the next round\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "# time_steps = 50\n",
    "# num_features=list(np.unique(labels))\n",
    "# # sequence_length = 5  # Number of previous rounds to consider as input\n",
    "# for i in range(len(data) - time_steps):\n",
    "#     # print(\"-------------------\")\n",
    "#     # print(data.iloc[i:i+sequence_length].drop(columns=['Group']).values)\n",
    "#     X.append(data.iloc[i:i+time_steps].drop(columns=['Group']).values)# Features (all columns except 'series')\n",
    "#     y.append(data.iloc[i+time_steps]['Group'])  # Target (next round's 'series')\n",
    "\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "\n",
    "# # Reshape X for LSTM [samples, time steps, features]\n",
    "# X = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "# num_features = X.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dozen\n",
       "1    22014\n",
       "2    21870\n",
       "3    21641\n",
       "0     1877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"dozen\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split (No separate validation set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66718, 10, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)  # Expected: (number_of_samples, time_steps, num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X\n",
    "y_train=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the LSTM Model\n",
    "# model = Sequential([\n",
    "#     LSTM(64, activation='tanh', return_sequences=True, input_shape=(time_steps, X_train.shape[2])),\n",
    "#     Dropout(0.2),\n",
    "#     LSTM(32, activation='tanh'),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     Dense(3, activation='softmax')  # Use 4 units for 4 classes (0, 1, 2, 3)\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # ================================\n",
    "# # Step 3: Train the Model\n",
    "# # ================================\n",
    "# # Callbacks for early stopping and saving the best model\n",
    "# early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "# model_checkpoint = ModelCheckpoint('best_model_odd_even.keras', monitor='loss', save_best_only=True)\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     epochs=50,\n",
    "#     batch_size=32,\n",
    "#     callbacks=[early_stopping, model_checkpoint]\n",
    "# )\n",
    "\n",
    "# # Evaluate the model\n",
    "# accuracy = model.evaluate(X_test, y_test)\n",
    "# print(f\"Test Accuracy: {accuracy[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "series\n",
       "-0.990850    30894\n",
       " 1.292836    21981\n",
       " 0.150993    14527\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"series\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "# # ================================\n",
    "# # Step 2: Build the LSTM Model\n",
    "# # ================================\n",
    "# num_classes = 3  # Number of classes\n",
    "# time_steps = X_train.shape[1]\n",
    "# num_features = X_train.shape[2]\n",
    "\n",
    "# model = Sequential([\n",
    "#     LSTM(32, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.01), input_shape=(time_steps, num_features)),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "#     Dense(num_classes, activation='softmax')  # Use softmax for multi-class classification\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # ================================\n",
    "# # Step 3: Train the Model\n",
    "# # ================================\n",
    "# # Callbacks for early stopping, model checkpoint, and learning rate reduction\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "# lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     validation_split=0.2,\n",
    "#     epochs=50,\n",
    "#     batch_size=32,\n",
    "#     callbacks=[early_stopping, model_checkpoint, lr_scheduler]\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"dozen\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3242 - loss: 1.2175\n",
      "Epoch 2/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3271 - loss: 1.1964\n",
      "Epoch 3/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3258 - loss: 1.1972\n",
      "Epoch 4/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3247 - loss: 1.1969\n",
      "Epoch 5/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3219 - loss: 1.1969\n",
      "Epoch 6/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.3254 - loss: 1.1936\n",
      "Epoch 7/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.3197 - loss: 1.1964\n",
      "Epoch 8/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3249 - loss: 1.1947\n",
      "Epoch 9/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3283 - loss: 1.1959\n",
      "Epoch 10/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3223 - loss: 1.1949\n",
      "Epoch 11/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3288 - loss: 1.1935\n",
      "Epoch 12/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3248 - loss: 1.1965\n",
      "Epoch 13/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3256 - loss: 1.1972\n",
      "Epoch 14/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3274 - loss: 1.1942\n",
      "Epoch 15/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3296 - loss: 1.1975\n",
      "Epoch 16/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.3293 - loss: 1.1965\n",
      "Epoch 17/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3296 - loss: 1.1984\n",
      "Epoch 18/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3293 - loss: 1.1920\n",
      "Epoch 19/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3361 - loss: 1.1937\n",
      "Epoch 20/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3411 - loss: 1.1934\n",
      "Epoch 21/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.3385 - loss: 1.1938\n",
      "Epoch 22/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3408 - loss: 1.1925\n",
      "Epoch 23/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3439 - loss: 1.1905\n",
      "Epoch 24/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3461 - loss: 1.1885\n",
      "Epoch 25/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.3461 - loss: 1.1866\n",
      "Epoch 26/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3518 - loss: 1.1852\n",
      "Epoch 27/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3586 - loss: 1.1832\n",
      "Epoch 28/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3594 - loss: 1.1784\n",
      "Epoch 29/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3626 - loss: 1.1759\n",
      "Epoch 30/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3646 - loss: 1.1752\n",
      "Epoch 31/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3679 - loss: 1.1709\n",
      "Epoch 32/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3723 - loss: 1.1674\n",
      "Epoch 33/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3728 - loss: 1.1676\n",
      "Epoch 34/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3806 - loss: 1.1613\n",
      "Epoch 35/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3810 - loss: 1.1579\n",
      "Epoch 36/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.3821 - loss: 1.1536\n",
      "Epoch 37/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3872 - loss: 1.1498\n",
      "Epoch 38/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3886 - loss: 1.1493\n",
      "Epoch 39/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3978 - loss: 1.1433\n",
      "Epoch 40/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3958 - loss: 1.1408\n",
      "Epoch 41/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.3953 - loss: 1.1410\n",
      "Epoch 42/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.4018 - loss: 1.1345\n",
      "Epoch 43/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4077 - loss: 1.1299\n",
      "Epoch 44/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4053 - loss: 1.1291\n",
      "Epoch 45/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4073 - loss: 1.1262\n",
      "Epoch 46/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.4151 - loss: 1.1207\n",
      "Epoch 47/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4152 - loss: 1.1199\n",
      "Epoch 48/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4115 - loss: 1.1180\n",
      "Epoch 49/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4119 - loss: 1.1172\n",
      "Epoch 50/50\n",
      "\u001b[1m1053/1053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4194 - loss: 1.1126\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5116 - loss: 1.0490\n",
      "Test Accuracy: 49.11%\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "num_classes = data[\"dozen\"].nunique()  # Number of classes\n",
    "time_steps = 10\n",
    "num_features = X_train.shape[2]\n",
    "\n",
    "# Build the LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', return_sequences=True, input_shape=(time_steps, num_features)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  # Use 4 units for 4 classes (0, 1, 2, 3)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ================================\n",
    "# Step 3: Train the Model\n",
    "# ================================\n",
    "# Callbacks for early stopping and saving the best model\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model_odd_even.keras', monitor='loss', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 49.11%\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 4: Evaluate the Model\n",
    "# ================================\n",
    "accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {accuracy[1] * 100:.2f}%\")\n",
    "\n",
    "# # ================================\n",
    "# # Step 5: Visualize Training Results\n",
    "# # ================================\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Plot training and validation loss\n",
    "# plt.plot(history.history['loss'], label='Train Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# plt.legend()\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot training and validation accuracy\n",
    "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.legend()\n",
    "# plt.title('Accuracy')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dozen': LabelEncoder(),\n",
       " 'column': LabelEncoder(),\n",
       " 'parity': LabelEncoder(),\n",
       " 'color': LabelEncoder(),\n",
       " 'series': LabelEncoder(),\n",
       " 'group': LabelEncoder()}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the single predicted class\n",
    "# sample_prediction=model.predict(X_test)\n",
    "# sample_label = np.argmax(sample_prediction)\n",
    "# sample_pred=label_encoders[\"dozen\"].inverse_transform([sample_label])\n",
    "\n",
    "# print(f\"\\nPredicted Label for Sample Input: {sample_label} , {sample_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(674, 10, 5)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the single predicted class\n",
    "# sample_prediction=model.predict(X_test[6].reshape(1, time_steps, num_features))\n",
    "# sample_label = np.argmax(sample_prediction, axis=1)\n",
    "# sample_pred=label_encoders[\"series\"].inverse_transform([sample_label])\n",
    "\n",
    "# print(f\"\\nPredicted Label for Sample Input: {sample_label} , {sample_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "predicted_labels= np.argmax(y_pred, axis=1)\n",
    "predicted_labels=label_encoders[\"dozen\"].inverse_transform(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D3', '0', 'D3', 'D3', 'D2', 'D3', 'D2', 'D2', 'D2', 'D3', 'D1',\n",
       "       'D2', 'D3', 'D2', 'D1', 'D2', 'D2', 'D2', 'D1', 'D2', 'D2', 'D3',\n",
       "       'D1', 'D3', 'D3', '0', 'D1', 'D1', 'D1', 'D3', '0', 'D3', 'D2',\n",
       "       'D1', 'D3', 'D3', 'D2', 'D3', 'D2', 'D3', 'D2', 'D3', 'D3', 'D3',\n",
       "       'D3', 'D3', 'D3', 'D2', 'D3', 'D3', 'D3', 'D2', 'D3', 'D2', 'D1',\n",
       "       'D2', 'D3', 'D2', 'D3', 'D1', 'D3', 'D2', 'D2', 'D2', 'D1', 'D1',\n",
       "       'D1', 'D2', 'D1', 'D3', 'D2', 'D2', 'D3', 'D2', 'D2', 'D2', 'D1',\n",
       "       '0', 'D1', 'D2', 'D3', 'D2', 'D3', 'D2', 'D1', 'D3', 'D2', 'D1',\n",
       "       'D3', 'D2', 'D2', 'D1', 'D2', 'D3', 'D3', 'D1', 'D3', 'D1', 'D3',\n",
       "       'D2', 'D1', 'D2', 'D3', 'D3', 'D1', 'D3', 'D1', 'D1', 'D1', 'D2',\n",
       "       'D2', 'D2', 'D3', 'D2', 'D2', 'D1', 'D3', 'D2', 'D3', 'D1', 'D2',\n",
       "       'D3', 'D3', 'D2', 'D3', 'D3', 'D2', 'D2', 'D1', 'D1', 'D3', 'D3',\n",
       "       'D3', 'D3', 'D3', 'D3', 'D1', 'D2', 'D1', 'D3', 'D3', 'D1', 'D1',\n",
       "       'D1', 'D3', 'D1', 'D2', 'D2', 'D1', 'D2', 'D2', 'D2', 'D2', 'D2',\n",
       "       'D2', 'D2', 'D2', 'D1', 'D2', 'D2', 'D3', 'D3', 'D3', 'D3', 'D1',\n",
       "       'D2', 'D3', 'D3', 'D2', 'D3', 'D2', 'D3', 'D2', 'D3', 'D1', 'D3',\n",
       "       'D3', 'D3', 'D3', 'D1', 'D1', 'D3', 'D1', 'D3', '0', 'D2', 'D1',\n",
       "       'D3', 'D1', 'D3', 'D1', 'D3', 'D1', 'D3', 'D2', 'D3', 'D1', 'D3',\n",
       "       'D3', 'D3', 'D3', 'D3', 'D2', 'D3', 'D1', 'D1', 'D2', 'D1', 'D2',\n",
       "       'D3', 'D3', 'D1', 'D2', 'D3', 'D3', 'D2', 'D2', 'D3', 'D1', 'D1',\n",
       "       'D2', 'D1', 'D1', 'D3', 'D2', 'D2', 'D3', 'D1', 'D3', 'D2', 'D2',\n",
       "       'D1', 'D1', 'D1', 'D3', 'D2', 'D3', 'D1', 'D3', 'D3', 'D2', 'D2',\n",
       "       'D1', 'D3', 'D3', 'D3', 'D2', 'D2', 'D1', 'D2', 'D2', 'D2', 'D3',\n",
       "       'D3', 'D1', 'D2', 'D2', 'D1', 'D3', 'D1', 'D1', 'D3', 'D3', 'D3',\n",
       "       'D1', 'D3', 'D3', 'D1', 'D3', 'D1', 'D3', 'D2', 'D2', 'D2', 'D1',\n",
       "       'D3', 'D3', 'D3', 'D1', 'D1', 'D2', 'D2', 'D2', 'D3', 'D2', 'D2',\n",
       "       'D3', 'D1', 'D1', 'D1', 'D3', 'D1', 'D3', 'D2', 'D1', 'D3', 'D3',\n",
       "       'D3', 'D3', 'D3', 'D2', 'D2', 'D2', 'D1', 'D3', 'D1', 'D2', 'D2',\n",
       "       'D2', 'D1', 'D3', 'D3', 'D2', 'D2', 'D1', 'D3', 'D2', 'D3', 'D1',\n",
       "       'D3', 'D2', 'D3', 'D1', 'D3', 'D3', 'D3', 'D3', 'D3', 'D1', 'D2',\n",
       "       'D2', 'D3', 'D3', 'D1', 'D2', 'D1', 'D2', 'D2', 'D1', 'D2', 'D3',\n",
       "       'D1', 'D1', 'D3', 'D1', 'D3', 'D2', 'D3', 'D3', 'D3', 'D1', 'D1',\n",
       "       'D3', 'D2', 'D3', 'D1', 'D1', 'D3', 'D2', 'D1', '0', 'D1', 'D2',\n",
       "       'D2', 'D3', 'D3', 'D2', 'D3', 'D2', 'D2', 'D1', 'D1', 'D3', 'D2',\n",
       "       'D2', 'D1', 'D2', 'D2', 'D3', 'D3', 'D1', 'D1', 'D2', 'D2', 'D1',\n",
       "       'D2', 'D1', '0', 'D2', 'D3', 'D1', 'D2', 'D1', 'D2', 'D3', 'D1',\n",
       "       'D3', 'D2', 'D1', 'D2', 'D2', 'D2', 'D1', 'D2', 'D3', 'D2', 'D1',\n",
       "       'D3', 'D3', 'D3', 'D1', 'D2', 'D2', 'D2', 'D1', 'D1', 'D2', 'D1',\n",
       "       'D1', 'D1', 'D2', 'D2', 'D1', 'D3', 'D2', 'D2', 'D3', 'D1', 'D1',\n",
       "       'D3', 'D2', 'D1', 'D2', 'D2', 'D3', 'D2', 'D2', 'D2', 'D3', 'D2',\n",
       "       'D1', 'D3', 'D2', 'D3', 'D3', 'D3', 'D1', 'D3', 'D1', 'D2', 'D1',\n",
       "       'D1', 'D2', 'D1', 'D2', 'D2', 'D3', 'D2', 'D3', 'D3', 'D2', 'D2',\n",
       "       'D3', 'D2', 'D2', 'D1', 'D1', 'D3', 'D2', 'D1', 'D1', 'D2', 'D1',\n",
       "       'D3', 'D2', 'D2', 'D2', 'D3', 'D1', 'D3', 'D3', 'D1', 'D3', 'D3',\n",
       "       'D3', 'D2', 'D3', 'D2', 'D3', 'D2', 'D3', 'D3', 'D1', 'D3', 'D2',\n",
       "       'D1', 'D2', 'D2', 'D3', 'D3', 'D3', 'D3', 'D1', 'D2', 'D3', 'D3',\n",
       "       'D2', 'D1', 'D2', 'D3', 'D2', 'D3', 'D3', 'D1', 'D3', 'D1', 'D1',\n",
       "       'D2', 'D1', 'D3', 'D3', 'D1', 'D2', 'D3', 'D3', 'D2', 'D1', 'D1',\n",
       "       'D1', 'D1', 'D1', 'D2', 'D1', 'D3', 'D1', 'D1', 'D3', 'D3', 'D2',\n",
       "       'D2', 'D2', 'D2', 'D2', 'D1', 'D1', 'D3', 'D3', 'D3', 'D3', 'D2',\n",
       "       'D3', 'D1', 'D2', 'D1', 'D2', 'D1', 'D2', 'D3', 'D1', 'D2', 'D2',\n",
       "       'D3', 'D2', 'D3', 'D2', 'D1', 'D3', 'D3', 'D2', 'D1', 'D3', 'D3',\n",
       "       'D2', 'D1', 'D1', 'D1', 'D1', 'D3', 'D2', 'D3', 'D1', 'D2', 'D3',\n",
       "       'D2', 'D3', 'D3', 'D2', 'D2', 'D1', 'D3', 'D1', 'D1', 'D2', 'D3',\n",
       "       'D1', 'D2', 'D1', 'D1', 'D3', 'D3', 'D2', 'D3', 'D2', 'D2', 'D3',\n",
       "       'D2', 'D1', 'D2', 'D1', 'D3', 'D1', 'D3', 'D1', 'D3', 'D3', 'D1',\n",
       "       'D2', 'D3', 'D3', 'D3', 'D2', 'D1', 'D2', 'D3', 'D3', 'D3', 'D3',\n",
       "       'D3', 'D3', 'D1', 'D2', 'D2', 'D3', 'D1', 'D1', 'D1', 'D2', 'D1',\n",
       "       'D2', 'D1', 'D2', 'D2', 'D3', 'D3', 'D1', 'D1', 'D1', 'D2', 'D1',\n",
       "       'D3', 'D2', 'D2', 'D3', 'D1', 'D2', 'D2', 'D1', 'D1', 'D1', 'D3',\n",
       "       'D3', 'D3', 'D2', 'D1', 'D1', 'D2', 'D1', 'D2', 'D3', 'D3', 'D2',\n",
       "       'D1', 'D1', 'D3'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\n",
    "    \"Dozen_lstm_model_10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model1=load_model(\"lstm_series_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.46187592, 0.21285118, 0.32527292],\n",
       "       [0.46187642, 0.21284835, 0.3252752 ],\n",
       "       [0.4618772 , 0.21284874, 0.32527405],\n",
       "       ...,\n",
       "       [0.4618767 , 0.21284986, 0.32527354],\n",
       "       [0.46187755, 0.21284787, 0.32527456],\n",
       "       [0.4618779 , 0.21284777, 0.3252744 ]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ================================\n",
    "# # Step 4: Evaluate the Model\n",
    "# # ================================\n",
    "# # Evaluate on the test set\n",
    "# test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "# print(f\"Test Loss: {test_loss:.4f}\")\n",
    "# print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred_prob = model.predict(X_test)\n",
    "# y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# # Confusion Matrix\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# plt.figure(figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50, 5)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "X_test[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.08193769e+00,  6.20481932e-02, -9.37440845e-01,\n",
       "         -1.01310394e+00,  1.02729149e+00],\n",
       "        [ 6.91113935e-02,  1.21453727e+00, -9.37440845e-01,\n",
       "         -1.01310394e+00,  1.02729149e+00],\n",
       "        [-1.08193769e+00, -1.09044089e+00, -9.37440845e-01,\n",
       "         -1.01310394e+00, -9.73433549e-01],\n",
       "        [ 6.91113935e-02,  6.20481932e-02, -9.37440845e-01,\n",
       "         -1.01310394e+00,  1.02729149e+00],\n",
       "        [-2.23298677e+00, -2.24292996e+00, -9.37440845e-01,\n",
       "          1.03529102e-03, -9.73433549e-01],\n",
       "        [-1.08193769e+00, -1.09044089e+00, -9.37440845e-01,\n",
       "         -1.01310394e+00,  1.02729149e+00],\n",
       "        [ 6.91113935e-02,  6.20481932e-02,  1.02245846e+00,\n",
       "         -1.01310394e+00, -9.73433549e-01],\n",
       "        [ 6.91113935e-02,  1.21453727e+00,  1.02245846e+00,\n",
       "         -1.01310394e+00, -9.73433549e-01],\n",
       "        [ 6.91113935e-02,  6.20481932e-02, -9.37440845e-01,\n",
       "          1.01517452e+00,  1.02729149e+00],\n",
       "        [ 1.22016048e+00, -1.09044089e+00,  1.02245846e+00,\n",
       "         -1.01310394e+00,  1.02729149e+00],\n",
       "        [ 6.91113935e-02,  6.20481932e-02, -9.37440845e-01,\n",
       "          1.01517452e+00,  1.02729149e+00],\n",
       "        [-1.08193769e+00,  1.21453727e+00,  1.02245846e+00,\n",
       "          1.01517452e+00, -9.73433549e-01],\n",
       "        [ 6.91113935e-02,  1.21453727e+00, -9.37440845e-01,\n",
       "         -1.01310394e+00,  1.02729149e+00],\n",
       "        [ 6.91113935e-02,  6.20481932e-02,  1.02245846e+00,\n",
       "          1.01517452e+00,  1.02729149e+00],\n",
       "        [ 1.22016048e+00,  6.20481932e-02, -9.37440845e-01,\n",
       "         -1.01310394e+00, -9.73433549e-01],\n",
       "        [ 1.22016048e+00,  1.21453727e+00,  1.02245846e+00,\n",
       "          1.01517452e+00,  1.02729149e+00],\n",
       "        [-1.08193769e+00,  1.21453727e+00, -9.37440845e-01,\n",
       "         -1.01310394e+00,  1.02729149e+00],\n",
       "        [ 1.22016048e+00,  1.21453727e+00,  1.02245846e+00,\n",
       "         -1.01310394e+00,  1.02729149e+00],\n",
       "        [-1.08193769e+00,  1.21453727e+00, -9.37440845e-01,\n",
       "         -1.01310394e+00,  1.02729149e+00],\n",
       "        [ 6.91113935e-02, -1.09044089e+00,  1.02245846e+00,\n",
       "         -1.01310394e+00,  1.02729149e+00],\n",
       "        [-1.08193769e+00,  6.20481932e-02, -9.37440845e-01,\n",
       "         -1.01310394e+00, -9.73433549e-01],\n",
       "        [ 1.22016048e+00,  6.20481932e-02, -9.37440845e-01,\n",
       "          1.01517452e+00, -9.73433549e-01],\n",
       "        [ 6.91113935e-02,  1.21453727e+00, -9.37440845e-01,\n",
       "          1.01517452e+00, -9.73433549e-01],\n",
       "        [ 1.22016048e+00,  6.20481932e-02, -9.37440845e-01,\n",
       "         -1.01310394e+00, -9.73433549e-01],\n",
       "        [ 1.22016048e+00,  1.21453727e+00, -9.37440845e-01,\n",
       "          1.01517452e+00,  1.02729149e+00],\n",
       "        [-2.23298677e+00, -2.24292996e+00, -9.37440845e-01,\n",
       "          1.03529102e-03, -9.73433549e-01],\n",
       "        [ 1.22016048e+00, -1.09044089e+00,  1.02245846e+00,\n",
       "          1.01517452e+00, -9.73433549e-01],\n",
       "        [ 6.91113935e-02,  6.20481932e-02, -9.37440845e-01,\n",
       "         -1.01310394e+00,  1.02729149e+00],\n",
       "        [ 1.22016048e+00,  1.21453727e+00, -9.37440845e-01,\n",
       "          1.01517452e+00,  1.02729149e+00],\n",
       "        [-1.08193769e+00, -1.09044089e+00, -9.37440845e-01,\n",
       "         -1.01310394e+00, -9.73433549e-01],\n",
       "        [ 6.91113935e-02,  6.20481932e-02,  1.02245846e+00,\n",
       "         -1.01310394e+00, -9.73433549e-01],\n",
       "        [-1.08193769e+00,  6.20481932e-02,  1.02245846e+00,\n",
       "          1.01517452e+00,  1.02729149e+00],\n",
       "        [ 1.22016048e+00, -1.09044089e+00,  1.02245846e+00,\n",
       "         -1.01310394e+00,  1.02729149e+00],\n",
       "        [-1.08193769e+00,  6.20481932e-02,  1.02245846e+00,\n",
       "         -1.01310394e+00,  1.02729149e+00],\n",
       "        [ 1.22016048e+00,  1.21453727e+00,  1.02245846e+00,\n",
       "          1.01517452e+00,  1.02729149e+00],\n",
       "        [-1.08193769e+00, -1.09044089e+00,  1.02245846e+00,\n",
       "          1.01517452e+00,  1.02729149e+00],\n",
       "        [ 1.22016048e+00,  1.21453727e+00, -9.37440845e-01,\n",
       "          1.01517452e+00,  1.02729149e+00],\n",
       "        [ 6.91113935e-02,  6.20481932e-02, -9.37440845e-01,\n",
       "          1.01517452e+00,  1.02729149e+00],\n",
       "        [ 6.91113935e-02,  1.21453727e+00,  1.02245846e+00,\n",
       "          1.01517452e+00, -9.73433549e-01],\n",
       "        [-1.08193769e+00,  1.21453727e+00,  1.02245846e+00,\n",
       "          1.01517452e+00, -9.73433549e-01],\n",
       "        [ 1.22016048e+00, -1.09044089e+00, -9.37440845e-01,\n",
       "         -1.01310394e+00, -9.73433549e-01],\n",
       "        [ 6.91113935e-02,  6.20481932e-02, -9.37440845e-01,\n",
       "          1.01517452e+00,  1.02729149e+00],\n",
       "        [-1.08193769e+00,  1.21453727e+00,  1.02245846e+00,\n",
       "          1.01517452e+00, -9.73433549e-01],\n",
       "        [ 1.22016048e+00,  6.20481932e-02, -9.37440845e-01,\n",
       "          1.01517452e+00, -9.73433549e-01],\n",
       "        [ 1.22016048e+00,  1.21453727e+00,  1.02245846e+00,\n",
       "          1.01517452e+00,  1.02729149e+00],\n",
       "        [-2.23298677e+00, -2.24292996e+00, -9.37440845e-01,\n",
       "          1.03529102e-03, -9.73433549e-01],\n",
       "        [-1.08193769e+00,  1.21453727e+00,  1.02245846e+00,\n",
       "          1.01517452e+00, -9.73433549e-01],\n",
       "        [ 6.91113935e-02,  1.21453727e+00, -9.37440845e-01,\n",
       "          1.01517452e+00, -9.73433549e-01],\n",
       "        [-1.08193769e+00, -1.09044089e+00,  1.02245846e+00,\n",
       "          1.01517452e+00, -9.73433549e-01],\n",
       "        [-1.08193769e+00, -1.09044089e+00, -9.37440845e-01,\n",
       "         -1.01310394e+00, -9.73433549e-01]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Predict on the test set\n",
    "# y_pred_prob = model.predict(X_test[:1])\n",
    "# y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "# print(y_pred)\n",
    "# y_pred=label_encoders[\"odd/even\"].inverse_transform(y_pred)\n",
    "\n",
    "# # # Save the model\n",
    "# model.save(\"lstm_model_ODD_EVEN.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=pd.read_excel(\"NEW DATA SHEET (copy) with features.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# # Load the trained model\n",
    "# model_path = \"best_model2.keras\"\n",
    "# model = load_model(model_path)\n",
    "# print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.46142247, 0.21467936, 0.32389817]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Dozen</th>\n",
       "      <th>Column</th>\n",
       "      <th>odd/even</th>\n",
       "      <th>red / black</th>\n",
       "      <th>series</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>D 1</td>\n",
       "      <td>C 3</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>B</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number Dozen Column odd/even red / black series Group\n",
       "0       6   D 1    C 3     EVEN       BLACK      B    G2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n",
      "Predicted Probabilities: [0.46145624 0.21465917 0.32388455]\n",
      "Predicted Labels: 0\n",
      "Decoded Labels: A\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# ================================\n",
    "# Step 1: Load the Trained Model\n",
    "# ================================\n",
    "def load_trained_model(model_path):\n",
    "    \"\"\"Load the trained model from a file.\"\"\"\n",
    "    model = load_model(model_path)\n",
    "    print(\"Model loaded successfully.\")\n",
    "    return model\n",
    "\n",
    "# ================================\n",
    "# Step 2: Preprocess Input Data\n",
    "# ================================\n",
    "def preprocess_input(input_data):\n",
    "    \"\"\"Preprocess input data to match the model's expected shape.\"\"\"\n",
    "    # Ensure input_data is a NumPy array\n",
    "\n",
    "    categorical_columns=['Dozen', 'Column', 'odd/even', 'red / black', 'series', \"Group\"]\n",
    "\n",
    "    # Convert all categorical columns to strings to ensure uniformity\n",
    "    input_data[categorical_columns] = input_data[categorical_columns].astype(str)\n",
    "    #Preprocess categorical columns\n",
    "    input_data = input_data.drop([\"Number\"], axis=1)\n",
    "    input_data[\"Dozen\"].replace({\"D 1\":\"D1\", \"D 2\":\"D2\", \"D 3\":\"D3\"}, inplace=True)\n",
    "    input_data[\"Column\"].replace({\"C 1\":\"C1\", \"C 2\":\"C2\", \"C 3\":\"C3\"}, inplace=True)\n",
    "    input_data[\"odd/even\"].replace({\"nan\":\"0\"}, inplace=True)\n",
    "\n",
    "    label_encoders = {}\n",
    "    for column in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        input_data[column] = le.fit_transform(input_data[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "    #Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    input_data[['Dozen', 'Column', 'Group', 'red / black', 'odd/even']] = scaler.fit_transform(input_data[['Dozen', 'Column', 'Group', 'red / black', 'odd/even']])\n",
    "    # Fill missing values if necessary\n",
    "    input_data = input_data.fillna(0)\n",
    "    ## Converting Data Time Series\n",
    "    # X = []\n",
    "    # y=[]\n",
    "    time_steps = 50\n",
    "    # data=data.drop([\"Number\"], axis=1)\n",
    "    X=input_data.drop(columns=['series']).values\n",
    "    X= np.array(X)\n",
    "    # y = np.array(y)\n",
    "    # print(X.shape)\n",
    "    X = X.reshape(1, X.shape[0], X.shape[1])\n",
    "    # input_data = np.array(input_data)\n",
    "\n",
    "    return X \n",
    "\n",
    "# ================================\n",
    "# Step 3: Perform Inference\n",
    "# ================================\n",
    "def predict_class(model, X):\n",
    "    \"\"\"Predict class probabilities and labels for the input data.\"\"\"\n",
    "    # Get probabilities\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    # Convert probabilities to binary labels (0 or 1)\n",
    "    # predicted_labels = (probabilities > 0.5).astype(int)\n",
    "    # print(predicted_labels)\n",
    "    predicted_labels = np.argmax(predictions).astype(list)\n",
    "    decoded_labels = label_encoders[\"series\"].inverse_transform([predicted_labels])\n",
    "    \n",
    "    return predictions, predicted_labels ,decoded_labels\n",
    "# ================================\n",
    "# Step 4: Main Inference Script\n",
    "# ================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the trained model\n",
    "    model_path = \"lstm_series_model.h5\"\n",
    "\n",
    "    # Load the model\n",
    "    model = load_trained_model(model_path)\n",
    "\n",
    "    # Example input data (replace with actual test input)\n",
    "    # Example assumes time_steps=10, num_features=5\n",
    "    \n",
    "    sample_input =data2[50:101]  # Replace with your actual data\n",
    "\n",
    "    # Preprocess input data\n",
    "    preprocessed_input = preprocess_input(sample_input)\n",
    "\n",
    "    # Perform inference\n",
    "    probabilities, predicted_labels,decoded_labels = predict_class(model, preprocessed_input)\n",
    "\n",
    "    # Output the results\n",
    "    print(\"Predicted Probabilities:\", probabilities[-1])\n",
    "    print(\"Predicted Labels:\", predicted_labels)\n",
    "    print(\"Decoded Labels:\", decoded_labels[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Dozen</th>\n",
       "      <th>Column</th>\n",
       "      <th>odd/even</th>\n",
       "      <th>red / black</th>\n",
       "      <th>series</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2</td>\n",
       "      <td>D 1</td>\n",
       "      <td>C 2</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>21</td>\n",
       "      <td>D 2</td>\n",
       "      <td>C 3</td>\n",
       "      <td>ODD</td>\n",
       "      <td>RED</td>\n",
       "      <td>A</td>\n",
       "      <td>G1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number Dozen Column odd/even red / black series Group\n",
       "101       2   D 1    C 2     EVEN       BLACK      A    G1\n",
       "102      21   D 2    C 3      ODD         RED      A    G1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Dozen</th>\n",
       "      <th>Column</th>\n",
       "      <th>odd/even</th>\n",
       "      <th>red / black</th>\n",
       "      <th>series</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>D 1</td>\n",
       "      <td>C 3</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>B</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number Dozen Column odd/even red / black series Group\n",
       "0       6   D 1    C 3     EVEN       BLACK      B    G2"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6777578]], dtype=float32)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(preprocessed_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # ================================\n",
    "# # Step 1: Load the Trained Model\n",
    "# # ================================\n",
    "# def load_trained_model(model_path):\n",
    "#     \"\"\"Load the trained model from a file.\"\"\"\n",
    "#     model = load_model(model_path)\n",
    "#     print(\"Model loaded successfully.\")\n",
    "#     return model\n",
    "\n",
    "# # ================================\n",
    "# # Step 2: Preprocess Input Data\n",
    "# # ================================\n",
    "# def preprocess_input(input_data, label_encoders, time_steps, num_features):\n",
    "#     \"\"\"Preprocess input data to match the model's expected shape.\"\"\"\n",
    "#     # Ensure input_data is a DataFrame\n",
    "#     categorical_columns = ['Dozen', 'Column', 'odd/even', 'red / black', 'series', 'Group']\n",
    "\n",
    "#     # Convert all categorical columns to strings to ensure uniformity\n",
    "#     input_data[categorical_columns] = input_data[categorical_columns].astype(str)\n",
    "\n",
    "#     # Convert all categorical columns to strings to ensure uniformity\n",
    "#     input_data[categorical_columns] = input_data[categorical_columns].astype(str)\n",
    "#     #Preprocess categorical columns\n",
    "#     input_data = input_data.drop([\"Number\"], axis=1)\n",
    "#     input_data[\"Dozen\"].replace({\"D 1\":\"D1\", \"D 2\":\"D2\", \"D 3\":\"D3\"}, inplace=True)\n",
    "#     input_data[\"Column\"].replace({\"C 1\":\"C1\", \"C 2\":\"C2\", \"C 3\":\"C3\"}, inplace=True)\n",
    "#     input_data[\"odd/even\"].replace({\"nan\":\"0\"}, inplace=True)\n",
    "    \n",
    "#     # Encoding categorical columns\n",
    "#     for column in categorical_columns:\n",
    "#         input_data[column] = label_encoders[column].transform(input_data[column])\n",
    "    \n",
    "#     # Normalize 'Dozen', \"series\" and 'Column' values\n",
    "#     scaler = StandardScaler()\n",
    "#     input_data[['Dozen', 'Column', 'odd/even', 'red / black', 'series']] = scaler.fit_transform(input_data[['Dozen', 'Column', 'odd/even', 'red / black', 'series']])\n",
    "\n",
    "#     # Fill missing values if necessary\n",
    "#     input_data = input_data.fillna(0)\n",
    "\n",
    "#     # Converting Data Time Series\n",
    "#     X = input_data.drop(columns=['Group'])\n",
    "#     y = input_data['Group']\n",
    "\n",
    "#     if len(X) < time_steps:\n",
    "#         padding = pd.DataFrame(np.zeros((time_steps - len(X), num_features)))\n",
    "#         X = pd.concat([padding, X], ignore_index=True)\n",
    "#     X = np.array(X.values)\n",
    "#     y = np.array(y.values)\n",
    "#     X.reshape(1, time_steps, num_features)\n",
    "\n",
    "#     return X, y\n",
    "\n",
    "# # ================================\n",
    "# # Step 3: Perform Inference\n",
    "# # ================================\n",
    "# def predict_class(model, X):\n",
    "#     \"\"\"Predict class probabilities and labels for the input data.\"\"\"\n",
    "#     # Get probabilities\n",
    "#     probabilities = model.predict(X)\n",
    "\n",
    "#     # Convert probabilities to binary labels (0 or 1)\n",
    "#     predicted_labels = (probabilities > 0.5).astype(int)\n",
    "#     return probabilities, predicted_labels\n",
    "\n",
    "# # ================================\n",
    "# # Step 4: Main Inference Script\n",
    "# # ================================\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Path to the trained model\n",
    "#     model_path = \"lstm_model.h5\"\n",
    "\n",
    "#     # Load the model\n",
    "#     model = load_trained_model(model_path)\n",
    "\n",
    "#     # Example input data (replace with actual test input)\n",
    "#     sample_input = pd.read_excel(\"NEW DATA SHEET (copy) with features.xlsx\")[:1]  # Replace with your actual data\n",
    "#     time_steps = 50\n",
    "#     num_features = 5\n",
    "#     # Preprocess input data\n",
    "#     X, y = preprocess_input(sample_input, label_encoders, time_steps, num_features)\n",
    "\n",
    "#     # Perform inference\n",
    "#     probabilities, predicted_labels = predict_class(model, X)\n",
    "\n",
    "#     # Output the results\n",
    "#     print(\"Predicted Probabilities:\", probabilities)\n",
    "#     print(\"Predicted Labels:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
